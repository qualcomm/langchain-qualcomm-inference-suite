{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "sidebar_label: Qualcomm Inference Suite\n",
    "---"
   ],
   "id": "f62bbab19ae5ef33"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# ChatQIS\n",
    "\n",
    "This will help you getting started with Qualcomm Inference Suite [chat models](/docs/concepts/chat_models). For detailed documentation of all ChatQIS features and configurations head to the [API reference](https://python.langchain.com/api_reference/langchain_qualcomm_inference_suite/chat_models/langchain_qualcomm_inference_suite.chat_models.ChatQIS.html).\n",
    "\n",
    "## Overview\n",
    "### Integration details\n",
    "\n",
    "| Class                                                                                                                                                            | Package                                                                                                              | Local | Serializable | JS support |                                                 Package downloads                                                  |                                                 Package latest                                                  |\n",
    "|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------|:---------------------------------------------------------------------------------------------------------------------|:-----:|:------------:|:----------:|:------------------------------------------------------------------------------------------------------------------:|:---------------------------------------------------------------------------------------------------------------:|\n",
    "| [ChatQIS](https://python.langchain.com/api_reference/langchain_qualcomm_inference_suite/chat_models/langchain_qualcomm_inference_suite.chat_models.ChatQIS.html) | [langchain-qualcomm-inference-suite](https://python.langchain.com/api_reference/langchain_qualcomm_inference_suite/) |   ❌   |      ❌       |     ❌      | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-qualcomm-inference-suite?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-qualcomm-inference-suite?style=flat-square&label=%20) |\n",
    "\n",
    "### Model features\n",
    "| [Tool calling](/docs/how_to/tool_calling) | [Structured output](/docs/how_to/structured_output/) | JSON mode | [Image input](/docs/how_to/multimodal_inputs/) | Audio input | Video input | [Token-level streaming](/docs/how_to/chat_streaming/) | Native async | [Token usage](/docs/how_to/chat_token_usage_tracking/) | [Logprobs](/docs/how_to/logprobs/) |\n",
    "|:-----------------------------------------:|:----------------------------------------------------:|:---------:|:----------------------------------------------:|:-----------:|:-----------:|:-----------------------------------------------------:|:------------:|:------------------------------------------------------:|:----------------------------------:|\n",
    "|                     ❌                     |                          ❌                           |     ❌     |                       ❌                        |      ❌      |      ❌      |                           ✅                           |      ✅       |                           ✅                            |                 ❌                  |\n",
    "\n",
    "## Setup\n",
    "\n",
    "To access Qualcomm Inference Suite models please reach out to your Qualcomm Inference Suite service provider for support. They will provide you an API key and API endpoint. Then you can and install and make use of the `langchain-qualcomm-inference-suite` integration package.\n",
    "\n",
    "### Credentials\n",
    "\n",
    "Please reach out to your Qualcomm Inference Suite service provider for support to generate an API key and obtain the API endpoint. Once you've done this set the `IMAGINE_API_KEY` and `IMAGINE_API_ENDPOINT` environment variables:"
   ],
   "id": "65b0ede5fda5c362"
  },
  {
   "cell_type": "code",
   "id": "433e8d2b-9519-4b49-b2c4-7ab65b046c94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T20:24:33.209096Z",
     "start_time": "2025-04-10T18:47:01.357684Z"
    }
   },
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"IMAGINE_API_KEY\"):\n",
    "    os.environ[\"IMAGINE_API_KEY\"] = getpass.getpass(\"Enter your Qualcomm Inference Suite API key: \")\n",
    "if not os.getenv(\"IMAGINE_API_ENDPOINT\"):\n",
    "    os.environ[\"IMAGINE_API_ENDPOINT\"] = input(\"Enter your Qualcomm Inference Suite API endpoint: \")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "0730d6a1-c893-4840-9817-5e5251676d5d",
   "metadata": {},
   "source": [
    "### Installation\n",
    "\n",
    "The LangChain Qualcomm Inference Suite integration lives in the `langchain-qualcomm-inference-suite` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652d6238-1f87-422a-b135-f5abbb8652fc",
   "metadata": {},
   "outputs": [],
   "source": "%pip install -qU langchain-qualcomm-inference-suite"
  },
  {
   "cell_type": "markdown",
   "id": "a38cde65-254d-4219-a441-068766c0d4b5",
   "metadata": {},
   "source": [
    "## Instantiation\n",
    "\n",
    "Now we can instantiate our model object and generate chat completions:"
   ]
  },
  {
   "cell_type": "code",
   "id": "cb09c344-1836-4e0c-acf8-11d13ac1dbae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T20:24:41.729586Z",
     "start_time": "2025-04-10T20:24:39.879306Z"
    }
   },
   "source": [
    "from langchain_qualcomm_inference_suite import ChatQIS\n",
    "\n",
    "llm = ChatQIS(\n",
    "    model=\"Llama-3.1-8B\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "2b4f3e15",
   "metadata": {},
   "source": "## Invocation\n"
  },
  {
   "cell_type": "code",
   "id": "62e0dbc3",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-04-10T22:31:06.733830Z",
     "start_time": "2025-04-10T22:31:05.567345Z"
    }
   },
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The translation of \"I love programming\" to French is:\\n\\n\"J\\'adore le programmation.\"', additional_kwargs={}, response_metadata={'token_usage': {'prompt_tokens': 36, 'total_tokens': 58, 'completion_tokens': 22}, 'model_name': 'Llama-3.1-8B', 'system_fingerprint': '', 'finish_reason': <FinishReason.stop: 'stop'>}, id='run-984263a5-9ead-408f-8954-3659d3671d22-0', usage_metadata={'input_tokens': 36, 'output_tokens': 22, 'total_tokens': 58})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "d86145b3-bfef-46e8-b227-4dda5c9c2705",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T22:31:10.548635Z",
     "start_time": "2025-04-10T22:31:10.543914Z"
    }
   },
   "source": [
    "print(ai_msg.content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The translation of \"I love programming\" to French is:\n",
      "\n",
      "\"J'adore le programmation.\"\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "18e2bfc0-7e78-4528-a73f-499ac150dca8",
   "metadata": {},
   "source": [
    "## Chaining\n",
    "\n",
    "We can [chain](/docs/how_to/sequence/) our model with a prompt template like so:\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "e197d1d7-a070-4c96-9f8a-a0e86d046e0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T22:31:15.554387Z",
     "start_time": "2025-04-10T22:31:14.700932Z"
    }
   },
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant that translates {input_language} to {output_language}.\",\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"input_language\": \"English\",\n",
    "        \"output_language\": \"German\",\n",
    "        \"input\": \"I love programming.\",\n",
    "    }\n",
    ")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Das Programmieren ist mein Hobby.', additional_kwargs={}, response_metadata={'token_usage': {'prompt_tokens': 31, 'total_tokens': 39, 'completion_tokens': 8}, 'model_name': 'Llama-3.1-8B', 'system_fingerprint': '', 'finish_reason': <FinishReason.stop: 'stop'>}, id='run-89137506-a3a1-4799-bf8d-564a1a574dee-0', usage_metadata={'input_tokens': 31, 'output_tokens': 8, 'total_tokens': 39})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "3a5bb5ca-c3ae-4a58-be67-2cd18574b9a3",
   "metadata": {},
   "source": [
    "## API reference\n",
    "\n",
    "For detailed documentation of all ChatQIS features and configurations head to the [API reference](https://python.langchain.com/api_reference/langchain_qualcomm_inference_suite/chat_models/langchain_qualcomm_inference_suite.chat_models.ChatQIS.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
