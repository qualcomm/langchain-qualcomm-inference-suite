{
 "cells": [
  {
   "cell_type": "raw",
   "id": "10238e62-3465-4973-9279-606cbb7ccf16",
   "metadata": {},
   "source": [
    "---\n",
    "sidebar_label: Qualcomm AI Inference Suite\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f91f20",
   "metadata": {},
   "source": [
    "# ChatQIS\n",
    "\n",
    "This notebook provides a quick overview for getting started with Qualcomm AI Inference Suite [tools](/docs/integrations/tools/). For detailed documentation of all Qualcomm In features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/community/tools/langchain_community.tools.langchain_qualcomm_inference_suite.tool.ChatQIS.html).\n",
    "\n",
    "## Overview\n",
    "\n",
    "### Integration details\n",
    "\n",
    "- TODO: Make sure links and features are correct\n",
    "\n",
    "| Class                                                                                                                                                     | Package | Serializable | JS support |  Package latest |\n",
    "|:----------------------------------------------------------------------------------------------------------------------------------------------------------| :--- |:------------:|:----------:| :---: |\n",
    "| [ChatQIS](https://python.langchain.com/v0.2/api_reference/community/tools/langchain_community.tools.langchain_qualcomm_inference_suite.tool.ChatQIS.html) | [langchain-qualcomm-inference-suite](https://python.langchain.com/api_reference/langchain_qualcomm_inference_suite/) |      ❌       |     ❌      |  ![PyPI - Version](https://img.shields.io/pypi/v/langchain-qualcomm-inference-suite?style=flat-square&label=%20) |\n",
    "\n",
    "### Tool features\n",
    "\n",
    "| Non-streaming tool support | Streaming tool support |\n",
    "|:---------------------------|:-----------------------|\n",
    "| ✅                          | ❌                      |\n",
    "\n",
    "\n",
    "## Setup\n",
    "\n",
    "To access Qualcomm AI Inference Suite models please reach out to your Qualcomm AI Inference Suite service provider for support. They will provide you an API key and API endpoint. Then you can and install and make use of the `langchain-qualcomm-inference-suite` integration package.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15e9266",
   "metadata": {},
   "source": [
    "### Credentials\n",
    "\n",
    "Please reach out to your Qualcomm AI Inference Suite service provider for support to generate an API key and obtain the API endpoint. Once you've done this set the `IMAGINE_API_KEY` and `IMAGINE_API_ENDPOINT` environment variables:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0b178a2-8816-40ca-b57c-ccdd86dde9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"IMAGINE_API_KEY\"):\n",
    "    os.environ[\"IMAGINE_API_KEY\"] = getpass.getpass(\"Enter your Qualcomm AI Inference Suite API key: \")\n",
    "if not os.getenv(\"IMAGINE_API_ENDPOINT\"):\n",
    "    os.environ[\"IMAGINE_API_ENDPOINT\"] = input(\"Enter your Qualcomm AI Inference Suite API endpoint: \")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Installation\n",
    "\n",
    "The LangChain Qualcomm AI Inference Suite integration lives in the `langchain-qualcomm-inference-suite` package:"
   ],
   "id": "48d335fe61c592dd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "%pip install -qU langchain-qualcomm-inference-suite",
   "id": "d468560588573c46"
  },
  {
   "cell_type": "markdown",
   "id": "1c97218f-f366-479d-8bf7-fe9f2f6df73f",
   "metadata": {},
   "source": [
    "## Instantiation\n",
    "\n",
    "Now we can instantiate our model object and generate chat completions with tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b3ddfe9-ca79-494c-a7ab-1f56d9407a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_qualcomm_inference_suite import ChatQIS\n",
    "\n",
    "llm = ChatQIS(\n",
    "    model=\"Llama-3.3-70B\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74147a1a",
   "metadata": {},
   "source": "## Invocation\n"
  },
  {
   "cell_type": "code",
   "id": "f90e33a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T20:41:23.719506Z",
     "start_time": "2025-05-05T20:41:19.628748Z"
    }
   },
   "source": [
    "# This is usually generated by a model, but we'll create a tool call directly for demo purposes.\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_qualcomm_inference_suite import ChatQIS\n",
    "\n",
    "llm = ChatQIS(model=\"Llama-3.3-70B\")\n",
    "\n",
    "\n",
    "class GetWeather(BaseModel):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "\n",
    "    location: str = Field(..., description=\"The city and state, e.g. San Francisco, CA\")\n",
    "\n",
    "\n",
    "class GetPopulation(BaseModel):\n",
    "    \"\"\"Get the current population in a given location\"\"\"\n",
    "\n",
    "    location: str = Field(..., description=\"The city and state, e.g. San Francisco, CA\")\n",
    "\n",
    "\n",
    "llm_with_tools = llm.bind_tools([GetWeather, GetPopulation])\n",
    "\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=\"You are a helpful assistant that can access external functions. The responses from these function calls will be appended to this dialogue. Please provide responses based on the information from these function calls.\"\n",
    "    ),\n",
    "    HumanMessage(content=\"What is the current weather in NY?\"),\n",
    "]\n",
    "\n",
    "\n",
    "response = llm_with_tools.invoke(messages)\n",
    "print(response.tool_calls)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'GetWeather', 'args': {'location': 'New York, NY'}, 'id': 'c4f21f44-ee2b-4530-a08c-fcf492bf1d39', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "4ac8146c",
   "metadata": {},
   "source": [
    "## API reference\n",
    "\n",
    "For detailed documentation of all ChatQIS features and configurations head to the [API reference](https://python.langchain.com/api_reference/langchain_qualcomm_inference_suite/chat_models/langchain_qualcomm_inference_suite.chat_models.ChatQIS.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poetry-venv-311",
   "language": "python",
   "name": "poetry-venv-311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
